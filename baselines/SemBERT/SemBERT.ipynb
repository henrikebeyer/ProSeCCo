{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data directories for running the SemBERT model on locutions\n",
    "# please note that we will create a test.tsv and a dev.tsv since executing the SemBERT model seeks for these file names\n",
    "locution_df = pd.read_csv(\"SemBERT_data/SemBERT_locutions.tsv\", sep=\"\\t\")\n",
    "locution_df.to_csv(\"SemBERT_data/locutions/test.tsv\", index=False, sep=\"\\t\")\n",
    "locution_df.to_csv(\"SemBERT_data/locutions/dev.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the run_snli_predict.py from SemBERT you might want to change some parts of this call before running it to accomodate to your device\n",
    "# make sure you have the necessary packages for SemBERT installed\n",
    "# in case you run into version issues, you might want to install pytorch to the specified version after installing allennlp\n",
    "\n",
    "# produce 3 prediction files on locutions with SemBERT\n",
    "for i in range(1,4):\n",
    "    # the following call will run the call of run_snli_predict.py as it was run for the reported results in the paper\n",
    "    #! CUDA_VISIBLE_DEVICES=1 python SemBERT/run_snli_predict.py --data_dir SemBERT_data/locutions --task_name snli --eval_batch_size 32 --max_num_aspect 3 --do_predict --do_lower_case --bert_model SemBERT/snli_model_dir/ --output_dir SemBERT_eval/ --tagger_path SemBERT/srl_model_dir/\n",
    "    # the call above will produce a _pred_results.tsv in the snli_model_dir\n",
    "\n",
    "    # now, the created _pred_results.tsv files need to be moved to another directory before the predictions for propositions are created\n",
    "    preds = pd.read_csv(\"SemBERT/snli_model_dir/_pred_results.tsv\", sep=\"\\t\")\n",
    "    preds.to_csv(f\"SemBERT_eval/predictions/_pred_results_locutions_{i}.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data directories for running the SemBERT model on propositions\n",
    "# please note that we will create a test.tsv and a dev.tsv since executing the SemBERT model seeks for these file names\n",
    "proposition_df = pd.read_csv(\"SemBERT_data/SemBERT_propositions.tsv\", sep=\"\\t\")\n",
    "proposition_df.to_csv(\"SemBERT_data/propositions/test.tsv\", sep=\"Å£\", index=False)\n",
    "proposition_df.to_csv(\"SemBERT_data/propositions/dev.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce 3 prediction files on locutions with SemBERT\n",
    "for i in range(1,4):\n",
    "    # the following call will run the call of run_snli_predict.py as it was run for the reported results in the paper\n",
    "    #! CUDA_VISIBLE_DEVICES=1 python SemBERT/run_snli_predict.py --data_dir SemBERT_data/propositions --task_name snli --eval_batch_size 32 --max_num_aspect 3 --do_predict --do_lower_case --bert_model SemBERT/snli_model_dir/ --output_dir SemBERT_eval/ --tagger_path SemBERT/srl_model_dir/\n",
    "    # the call above will produce a _pred_results.tsv in the snli_model_dir\n",
    "\n",
    "    # now, the created _pred_results.tsv files need to be moved to another directory before the predictions for propositions are created\n",
    "    preds = pd.read_csv(\"SemBERT/snli_model_dir/_pred_results.tsv\", sep=\"\\t\")\n",
    "    preds.to_csv(f\"SemBERT_eval/predictions/_pred_results_propositions_{i}.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 33.3 +- 0.0\n",
      "acc: 52.6 +- 0.0\n",
      "f1: 33.9 +- 2.188180498112527\n",
      "acc: 52.1 +- 0.8894424920585502\n"
     ]
    }
   ],
   "source": [
    "# create evaluations for the runs on locutions and propositions\n",
    "\n",
    "result_df = pd.DataFrame(columns = [\"data_type\", \"F1\", \"F1_std\", \"accs\", \"accs_std\"])\n",
    "\n",
    "all_results_df = pd.DataFrame(columns = [\"data_type\", \"F1s\", \"accs\"])\n",
    "\n",
    "f1_means = []\n",
    "f1_stds = []\n",
    "acc_means = []\n",
    "acc_stds = []\n",
    "\n",
    "all_f1 = []\n",
    "all_acc = []\n",
    "all_types = []\n",
    "\n",
    "types = [\"locutions\", \"props\"]\n",
    "for ty in types:\n",
    "    accs = []\n",
    "    f1s = []\n",
    "    for i in range(1,4):\n",
    "        pred_file = f\"SemBERT_eval/predictions/_pred_results_{ty}_{i}.tsv\"\n",
    "        gold_file = \"../../data/CAPTURE_final_corpus/fullCorpus/CAPTURE_final.tsv\"\n",
    "\n",
    "        pred_df = pd.read_csv(pred_file, sep=\"\\t\")\n",
    "        gold_df = pd.read_csv(gold_file, sep=\"\\t\")\n",
    "\n",
    "        gold = list(gold_df[\"label\"])\n",
    "\n",
    "        pred = [1 if lab == \"contradiction\" else 0 for lab in pred_df[\"prediction\"]]\n",
    "\n",
    "        acc = accuracy_score(gold, pred)\n",
    "        f1 = f1_score(gold, pred)\n",
    "        \n",
    "        accs.append(acc)\n",
    "        f1s.append(f1)\n",
    "        all_types.append(ty)\n",
    "        all_f1.append(f1)\n",
    "        all_acc.append(acc)\n",
    "\n",
    "    f\"Results from SemBERT prediction on {ty}\"\n",
    "    print(\"f1:\", round((mean(f1s)*100),1), \"+-\", 100*np.std(np.asarray(f1s)))\n",
    "    print(\"acc:\", round(100*mean(accs),1), \"+-\", 100*np.std(np.asarray(accs)))\n",
    "\n",
    "    f1_means.append(mean(f1s))\n",
    "    f1_stds.append(np.std(np.asarray(f1s)))\n",
    "\n",
    "    acc_means.append(mean(accs))\n",
    "    acc_stds.append(np.std(np.asarray(accs)))\n",
    "\n",
    "result_df[\"data_type\"] = types\n",
    "result_df[\"F1\"] = f1_means\n",
    "result_df[\"F1_std\"] = f1_stds\n",
    "result_df[\"accs\"] = acc_means\n",
    "result_df[\"acc_std\"] = acc_stds\n",
    "\n",
    "#result_df.to_csv(\"SemBERT_eval/mean_eval_results.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "\n",
    "all_results_df[\"data_type\"] = all_types\n",
    "all_results_df[\"F1s\"] = all_f1\n",
    "all_results_df[\"accs\"] = all_acc\n",
    "\n",
    "#all_results_df.to_csv(\"SemBERT_eval/all_eval_results.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
